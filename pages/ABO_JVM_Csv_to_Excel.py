import streamlit as st
import pandas as pd
import pymongo
from datetime import datetime
import os
import re
from dotenv import load_dotenv
import io
from dateutil.relativedelta import relativedelta

# Chargement des variables d'environnement
load_dotenv()

# R√©cup√©ration des cl√©s d'API et connexion MongoDB depuis les variables d'environnement
mongo_uri = os.getenv("MONGODB_URI") or st.secrets.get("MONGODB_URI")

def robust_date_conversion(date_series):
    """Fonction am√©lior√©e pour la conversion des dates avec gestion de multiples formats"""
    # Copie des donn√©es pour pr√©server l'original
    cleaned_dates = date_series.astype(str).str.strip()
    
    # Liste des formats √† essayer (du plus sp√©cifique au plus g√©n√©ral)
    date_formats = [
        '%Y-%m-%dT%H:%M:%S%z',  # Format ISO avec fuseau horaire
        '%Y-%m-%dT%H:%M:%S',     # Format ISO sans fuseau horaire
        '%Y-%m-%d %H:%M:%S%z',   # Format standard avec fuseau horaire
        '%Y-%m-%d %H:%M:%S',     # Format standard sans fuseau horaire
        '%Y-%m-%d',              # Date simple
        '%d/%m/%Y %H:%M:%S',     # Format europ√©en avec heure
        '%d/%m/%Y',              # Format europ√©en simple
        '%m/%d/%Y %H:%M:%S',     # Format US avec heure
        '%m/%d/%Y',              # Format US simple
    ]
    
    # Convertir les dates en utilisant pandas
    result = pd.to_datetime(cleaned_dates, errors='coerce', utc=True)
    
    # Pour les dates qui n'ont pas √©t√© converties, essayons les formats sp√©cifiques
    mask = result.isna()
    if mask.any():
        problematic_dates = cleaned_dates[mask]
        
        # Essayer chaque format pour les dates probl√©matiques
        for date_format in date_formats:
            try:
                # Convertir uniquement les dates probl√©matiques restantes
                still_na = result.isna()
                temp_result = pd.to_datetime(cleaned_dates[still_na], format=date_format, errors='coerce')
                # Mettre √† jour seulement les valeurs qui ont √©t√© converties
                result[still_na] = temp_result
                # Si toutes les dates sont converties, sortir de la boucle
                if not result.isna().any():
                    break
            except Exception as e:
                continue
    
    # Supprimer les fuseaux horaires pour uniformisation
    if result.dt.tz is not None:
        result = result.dt.tz_localize(None)
    
    return result

def load_from_mongodb():
    """Charge les donn√©es des abonn√©s YouTube depuis MongoDB"""
    if not mongo_uri:
        st.error("L'URI MongoDB n'est pas configur√©. Veuillez v√©rifier vos variables d'environnement.")
        return pd.DataFrame()
    
    try:
        # Connexion √† MongoDB
        client = pymongo.MongoClient(mongo_uri)
        db = client.get_database()
        collection = db.users  # Assurez-vous que c'est le bon nom de collection
        
        # R√©cup√©ration des utilisateurs avec uniquement les nouveaux champs
        users = list(collection.find({}, {
            "_id": 0,  # Exclusion de l'ID MongoDB
            "customerID": 1,
            "deliveryName": 1,
            "deliveryAddress1": 1, 
            "deliveryAddress2": 1,
            "deliveryZip": 1,
            "deliveryCity": 1,
            "deliveryProvinceCode": 1,
            "deliveryCountryCode": 1,
            "billingCountry": 1,
            "quantity": 1,
            "discordId": 1,
            "username": 1
        }))
        
        if not users:
            st.warning("Aucun abonn√© YouTube trouv√© dans MongoDB.")
            return pd.DataFrame()
        
        # Conversion en DataFrame pandas
        df_youtube = pd.DataFrame(users)
        
        # Uniformiser les noms de colonnes pour le format final attendu par les transporteurs
        column_mapping = {
            "customerID": "ID",
            "deliveryName": "Customer name",
            "deliveryAddress1": "Delivery address 1",
            "deliveryAddress2": "Delivery address 2",
            "deliveryZip": "Delivery zip",
            "deliveryCity": "Delivery city",
            "deliveryProvinceCode": "Delivery province code",
            "deliveryCountryCode": "Delivery country code",
            "billingCountry": "Billing country",
            "quantity": "Delivery interval count"
        }
        
        # Renommer les colonnes pour correspondre au format attendu
        df_youtube = df_youtube.rename(columns=column_mapping)
        
        # Ajouter les colonnes manquantes pour la compatibilit√©
        for col in column_mapping.values():
            if col not in df_youtube.columns:
                df_youtube[col] = None
        
        # Ajouter la colonne Source pour distinguer ces entr√©es
        df_youtube['Source'] = 'YouTube'
        df_youtube['Status'] = 'ACTIVE'  # Tous les abonn√©s YouTube sont consid√©r√©s comme actifs
        df_youtube['Created at'] = datetime.now()  # Date actuelle comme date de cr√©ation
        
        # Ajouter Line title pour les abonn√©s YouTube (par d√©faut Abo 1 an)
        df_youtube['Line title'] = 'Abonnement Extra - Engagement minimum de 12 mois'
        
        # Ajouter Next order date pour les abonn√©s YouTube (dans 12 mois)
        df_youtube['Next order date'] = datetime.now() + relativedelta(months=12)
        
        st.success(f"‚úÖ **{len(df_youtube)} abonn√©s YouTube r√©cup√©r√©s avec succ√®s !**")
        return df_youtube
        
    except Exception as e:
        st.error(f"Erreur lors de la connexion √† MongoDB: {e}")
        return pd.DataFrame()

# Fonction d√©di√©e √† la suppression des entr√©es de test
def remove_test_entries(df):
    """Supprime toutes les entr√©es li√©es √† Brice N Guessan et son email"""
    if df.empty:
        return df
    
    initial_count = len(df)
    
    # Pattern pour le nom
    name_pattern = r"Brice N'?Guessan"
    name_mask = df['Customer name'].str.contains(name_pattern, case=False, na=False, regex=True)
    
    # Pattern pour l'email - v√©rifier si la colonne existe
    email_mask = pd.Series(False, index=df.index)
    email_columns = ['Email', 'Customer email', 'email']
    for email_col in email_columns:
        if email_col in df.columns:
            col_mask = df[email_col].str.contains('bnguessan@linkdigitalspirit.com', case=False, na=False)
            email_mask = email_mask | col_mask
    
    # Combiner les masques
    test_mask = name_mask | email_mask
    test_count = test_mask.sum()
    
    if test_count > 0:
        # Supprimer les entr√©es de test sans afficher de d√©tails
        df = df[~test_mask]
        st.info(f"‚ÑπÔ∏è {test_count} entr√©es de test ont √©t√© supprim√©es.")
    
    return df

def calculate_remaining_magazines(df):
    """Calcule le nombre de magazines restants pour chaque abonn√© bas√© sur Next order date"""
    
    # V√©rifier que les colonnes n√©cessaires existent
    if 'Line title' not in df.columns:
        st.warning("‚ö†Ô∏è Colonne 'Line title' manquante. Calcul des magazines restants impossible.")
        df['Magazines Restants'] = None
        return df
    
    # D√©terminer le type d'abonnement et le nombre total de magazines
    def get_total_magazines(line_title):
        if pd.isna(line_title):
            return 0
        line_title = str(line_title).lower()
        if 'flex' in line_title:
            return 1  # Sans engagement
        elif 'extra' in line_title or '1 an' in line_title or '12 mois' in line_title:
            return 12  # Engagement 12 num√©ros
        else:
            return 0  # Type inconnu
    
    today = datetime.now()
    
    def calculate_sent_magazines(row):
        try:
            total_magazines = get_total_magazines(row['Line title'])
            
            # Pour les abonnements Flex, utiliser Created at
            if total_magazines == 1:
                if 'Created at' in row and pd.notna(row['Created at']):
                    created_date = pd.to_datetime(row['Created at'])
                    
                    # D√©terminer la date du premier envoi
                    if created_date.day < 5:
                        first_delivery = datetime(created_date.year, created_date.month, 5)
                    else:
                        if created_date.month == 12:
                            first_delivery = datetime(created_date.year + 1, 1, 5)
                        else:
                            first_delivery = datetime(created_date.year, created_date.month + 1, 5)
                    
                    # Si le premier envoi n'a pas encore eu lieu
                    if first_delivery > today:
                        return 0
                    else:
                        return 1  # Flex = 1 seul magazine
                else:
                    return 0
            
            # Pour les abonnements 12 mois (Extra et 1 an), utiliser Next order date
            elif total_magazines == 12:
                if 'Next order date' not in row or pd.isna(row['Next order date']):
                    # Si pas de Next order date, utiliser Created at comme fallback
                    if 'Created at' in row and pd.notna(row['Created at']):
                        created_date = pd.to_datetime(row['Created at'])
                        cycle_start = created_date
                    else:
                        return 0
                else:
                    # Convertir Next order date
                    next_order_date = pd.to_datetime(row['Next order date'])
                    
                    # Calculer le d√©but du cycle actuel (12 mois avant next_order_date)
                    cycle_start = next_order_date - relativedelta(months=12)
                
                # D√©terminer la date du premier envoi du cycle actuel
                if cycle_start.day < 5:
                    first_delivery = datetime(cycle_start.year, cycle_start.month, 5)
                else:
                    # Mois suivant
                    if cycle_start.month == 12:
                        first_delivery = datetime(cycle_start.year + 1, 1, 5)
                    else:
                        first_delivery = datetime(cycle_start.year, cycle_start.month + 1, 5)
                
                # Si le premier envoi n'a pas encore eu lieu
                if first_delivery > today:
                    return 0
                
                # Compter le nombre d'envois depuis le premier envoi du cycle actuel
                months_diff = (today.year - first_delivery.year) * 12 + (today.month - first_delivery.month)
                
                # Si on est apr√®s le 5 du mois actuel
                if today.day >= 5:
                    magazines_sent = months_diff + 1
                else:
                    magazines_sent = months_diff
                
                # Limiter au nombre total de magazines du cycle
                magazines_sent = min(magazines_sent, total_magazines)
                
                return magazines_sent
            
            else:
                return 0
                
        except Exception as e:
            st.warning(f"Erreur lors du calcul pour une ligne : {e}")
            return 0
    
    # Appliquer les calculs
    df['Total magazines'] = df['Line title'].apply(get_total_magazines)
    df['Magazines envoy√©s'] = df.apply(calculate_sent_magazines, axis=1)
    df['Magazines Restants'] = df['Total magazines'] - df['Magazines envoy√©s']
    
    # S'assurer que le nombre restant n'est jamais n√©gatif
    df['Magazines Restants'] = df['Magazines Restants'].apply(lambda x: max(0, x))
    
    return df

def process_csv(uploaded_files, include_youtube=False):
    """Lit et traite plusieurs fichiers CSV, avec option d'inclure les abonn√©s YouTube."""
    all_dataframes = []

    for csv_file in uploaded_files:
        try:
            df = pd.read_csv(csv_file)
            st.write(f"‚úÖ Fichier {csv_file.name} charg√© : {len(df)} lignes")
            
            # Supprimer les entr√©es de test imm√©diatement apr√®s le chargement
            df = remove_test_entries(df)
            
            all_dataframes.append(df)
        except Exception as e:
            st.error(f"‚ùå Erreur lors du chargement de {csv_file.name}: {e}")
    
    if not all_dataframes:
        st.error("Aucun fichier CSV n'a pu √™tre charg√©.")
        return None, None

    # Fusionner tous les fichiers en un seul DataFrame
    df = pd.concat(all_dataframes, ignore_index=True)

    # V√©rifier tous les statuts uniques pr√©sents
    unique_statuses = df['Status'].unique()

    # V√©rifier les colonnes requises
    required_columns = ['ID', 'Created at', 'Status', 'Next order date', 'Customer name']
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        st.error(f"Colonnes manquantes dans les fichiers CSV: {', '.join(missing_columns)}")
        return None, None
    
    # Utiliser notre fonction robuste de conversion de dates
    original_count = len(df)
    df['Created at'] = robust_date_conversion(df['Created at'])
    
    # Convertir aussi Next order date
    df['Next order date'] = robust_date_conversion(df['Next order date'])
    
    # Supprimer les lignes avec des dates invalides
    df = df.dropna(subset=['Created at'])
    if len(df) < original_count:
        st.warning(f"‚ö†Ô∏è {original_count - len(df)} lignes avec des dates invalides ont √©t√© supprim√©es.")

    # üöÄ Filtrage : Suppression des abonnements cr√©√©s apr√®s le 5 du mois
    today = datetime.today()
    start_date = datetime(today.year, today.month, 5)

    df_before_filtering = len(df)

    # Calculer quels abonnements seront supprim√©s sans les afficher
    df_to_be_removed = df[df['Created at'] >= start_date].copy()
    removed_count = len(df_to_be_removed)

    # Cr√©er le bouton de t√©l√©chargement pour les abonnements supprim√©s si n√©cessaire
    if not df_to_be_removed.empty:
        removed_csv = df_to_be_removed.to_csv(index=False)
        st.download_button(
            label="üì• T√©l√©charger la liste des abonnements supprim√©s",
            data=removed_csv,
            file_name="abonnements_supprimes.csv",
            mime="text/csv",
            help="T√©l√©charger la liste des abonnements cr√©√©s apr√®s le 5 du mois"
        )

    # Continuer avec le filtrage normal
    df = df[df['Created at'] < start_date]
    df_after_filtering = len(df)

    st.write(f"‚úÖ **Abonnements apr√®s filtrage : {df_after_filtering} (Nombres d'abonnements cr√©es apr√®s le 5 du mois : {df_before_filtering - df_after_filtering})**")

    # Standardisation de la colonne 'Status'
    df['Status'] = df['Status'].str.upper()

    # Ajout de la colonne 'Source' pour Shopify
    df['Source'] = 'Shopify'

    # S√©paration initiale des abonnements par statut
    active_df = df[df['Status'] == 'ACTIVE']
    paused_df = df[df['Status'] == 'PAUSED']
    cancelled_df = df[df['Status'] == 'CANCELLED']

    # V√©rifier √† nouveau pour les entr√©es de test √† chaque √©tape
    active_df = remove_test_entries(active_df)
    cancelled_df = remove_test_entries(cancelled_df)

    # Filtrage sp√©cifique pour les abonnements annul√©s
    # Exclure les abonnements avec motifs d'annulation sp√©cifiques
    if 'Cancellation note' in cancelled_df.columns:
        # Liste des motifs d'annulation √† exclure
        exclusion_patterns = [
            'Remboursement',
            'Arr√™t abonnement',
            'Arr√™t d\'abonnement',
            'changer d\'abonnement',
            'Erreur du client',
            'r√©silier son abonnement',
            'annuler son abonnement',
            'pris deux fois',
            'd√©j√† un autre abonnement',
            'demande du client',
            'commande frauduleuse',
            'Test',
            'opt√© pour un abonnement',
            'ne pas renouveler',
            'souscrit deux fois',
            'Abonnement en double'
        ]
        
        # Cr√©er le pattern regex (| = OU)
        pattern = '|'.join(exclusion_patterns)
        
        # Filtrer avec case=False pour ignorer majuscules/minuscules
        exclusion_mask = cancelled_df['Cancellation note'].str.contains(pattern, case=False, na=False, regex=True)
        exclusion_count = exclusion_mask.sum()
        
        if exclusion_count > 0:
            # Filtrer pour ne garder que les abonnements sans motif d'exclusion
            cancelled_df = cancelled_df[~exclusion_mask]
            st.info(f"‚ÑπÔ∏è {exclusion_count} abonnements annul√©s ont √©t√© exclus (motifs d'annulation).")
    
    # Ensuite, continuer avec le filtrage par date
    try:
        # S'assurer que les dates n'ont pas de fuseau horaire
        if cancelled_df['Next order date'].dt.tz is not None:
            cancelled_df['Next order date'] = cancelled_df['Next order date'].dt.tz_localize(None)
        
        # D√©terminer le 5 du mois actuel
        today = datetime.today()
        cutoff_date = datetime(today.year, today.month, 5)
        
        # Filtrer les abonnements annul√©s qui ont une date de prochaine commande apr√®s le 5 du mois
        valid_cancelled_df = cancelled_df[cancelled_df['Next order date'] > cutoff_date]
        
        excluded_count = len(cancelled_df) - len(valid_cancelled_df)
        if excluded_count > 0:
            st.info(f"‚ÑπÔ∏è {excluded_count} abonnements annul√©s ont √©t√© exclus car leur prochaine date de commande est avant le 5 du mois.")
        
    except Exception as e:
        st.error(f"Erreur lors de l'analyse des dates de commande: {e}")
        valid_cancelled_df = cancelled_df.copy()  # En cas d'erreur, garder tous les abonnements annul√©s par pr√©caution
    
    # V√©rifier √† nouveau pour les entr√©es de test dans les cancelled valides
    valid_cancelled_df = remove_test_entries(valid_cancelled_df)

    # Int√©grer les abonn√©s YouTube si demand√©
    if include_youtube:
        youtube_df = load_from_mongodb()
        if not youtube_df.empty:
            # Ajouter les abonn√©s YouTube aux abonn√©s actifs
            active_df = pd.concat([active_df, youtube_df], ignore_index=True)
            
            # V√©rifier une derni√®re fois apr√®s la fusion
            active_df = remove_test_entries(active_df)
            
            st.success(f"‚úÖ **{len(youtube_df)} abonn√©s YouTube ajout√©s aux abonn√©s actifs !**")
    
    return active_df, valid_cancelled_df

# Interface utilisateur Streamlit
st.title("Gestion des abonnements JV Magazine")
st.write("üëã Cet outil permet de traiter les abonnements Shopify et d'int√©grer les abonn√©s YouTube Discord.")

# Option pour inclure les abonn√©s YouTube
include_youtube = st.checkbox("Inclure les abonn√©s YouTube depuis MongoDB", value=False)

file_prefix = st.text_input("Entrez le pr√©fixe pour les fichiers finaux :", "")
uploaded_files = st.file_uploader("T√©l√©versez les fichiers CSV des abonnements", type="csv", accept_multiple_files=True)

if uploaded_files:
    with st.spinner("Traitement des donn√©es en cours..."):
        active_df, cancelled_df = process_csv(uploaded_files, include_youtube)

    if active_df is not None and cancelled_df is not None:
        # Afficher les statistiques
        st.write("## üìä Statistiques")
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("Abonnements actifs", len(active_df))
            if include_youtube:
                youtube_count = sum(active_df['Source'] == 'YouTube')
                shopify_count = sum(active_df['Source'] == 'Shopify')
                st.write(f"- Shopify: {shopify_count}")
                st.write(f"- YouTube: {youtube_count}")
        
        with col2:
            st.metric("Abonnements annul√©s", len(cancelled_df))
        
        # Section sp√©ciale pour les abonnements 1 an
        st.write("## üì¶ Analyse Abonnements 1 an")
        
        # Fonction pour d√©terminer si une adresse est en France
        def is_france(row):
            # V√©rifier d'abord le pays de livraison s'il existe
            if 'Delivery country code' in row and pd.notna(row['Delivery country code']):
                return row['Delivery country code'].upper() == 'FR'
            
            # V√©rifier le pays de livraison s'il existe
            if 'Delivery country' in row and pd.notna(row['Delivery country']):
                return 'FRANCE' in row['Delivery country'].upper()
            
            # V√©rifier la m√©thode de livraison s'il existe
            if 'Delivery Method' in row and pd.notna(row['Delivery Method']):
                return 'FR' in row['Delivery Method'].upper()
            
            # Par d√©faut, consid√©rer comme √©tranger si on ne peut pas d√©terminer
            return False
        
        # Fonction pour d√©terminer si une adresse est en Europe (hors France)
        def is_europe(row):
            if is_france(row):
                return False
            
            # Liste des codes pays europ√©ens (hors France)
            european_countries = [
                'AT', 'BE', 'BG', 'HR', 'CY', 'CZ', 'DK', 'EE', 'FI', 'DE', 
                'GR', 'HU', 'IE', 'IT', 'LV', 'LT', 'LU', 'MT', 'NL', 'PL', 
                'PT', 'RO', 'SK', 'SI', 'ES', 'SE', 'GB', 'CH', 'NO', 'IS'
            ]
            
            if 'Delivery country code' in row and pd.notna(row['Delivery country code']):
                return row['Delivery country code'].upper() in european_countries
            
            return False
        
        # S'assurer que valid_cancelled_df existe
        if 'valid_cancelled_df' not in locals() and 'valid_cancelled_df' not in globals():
            valid_cancelled_df = cancelled_df
        
        # Combiner actifs et annul√©s
        all_subs = pd.concat([active_df, valid_cancelled_df], ignore_index=True)
        
        # Calculer les magazines restants
        all_subs = calculate_remaining_magazines(all_subs)
        
        # Filtrer uniquement les abonnements "1 an"
        if 'Line title' in all_subs.columns:
            abo_1an_mask = all_subs['Line title'].str.contains('1 an', case=False, na=False, regex=True)
            abo_1an = all_subs[abo_1an_mask]
            
            if not abo_1an.empty:
                # R√©partition g√©ographique
                abo_1an_france = abo_1an[abo_1an.apply(is_france, axis=1)]
                abo_1an_europe = abo_1an[abo_1an.apply(is_europe, axis=1)]
                abo_1an_monde = abo_1an[~abo_1an.apply(is_france, axis=1) & ~abo_1an.apply(is_europe, axis=1)]
                
                # Calcul des magazines restants par zone
                magazines_france = int(abo_1an_france['Magazines Restants'].sum())
                magazines_europe = int(abo_1an_europe['Magazines Restants'].sum())
                magazines_monde = int(abo_1an_monde['Magazines Restants'].sum())
                
                # Prix par magazine selon la zone
                prix_magazine_france = 54.96 / 12  # 4.58‚Ç¨ par magazine
                prix_magazine_europe = 78.96 / 12  # 6.58‚Ç¨ par magazine
                prix_magazine_monde = 114.96 / 12  # 9.58‚Ç¨ par magazine
                
                # Calcul des dettes par zone
                dette_france = magazines_france * prix_magazine_france
                dette_europe = magazines_europe * prix_magazine_europe
                dette_monde = magazines_monde * prix_magazine_monde
                dette_totale = dette_france + dette_europe + dette_monde
                
                # Affichage des statistiques globales
                total_magazines_1an = magazines_france + magazines_europe + magazines_monde
                nombre_abonnes_1an = len(abo_1an)
                
                st.write("### üìä Vue d'ensemble")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("üë• Nombre d'abonn√©s 1 an", nombre_abonnes_1an)
                with col2:
                    st.metric("üìö Total magazines √† envoyer", total_magazines_1an)
                with col3:
                    st.metric("üí∞ Dette totale estim√©e", f"{dette_totale:.2f} ‚Ç¨")
                
                # R√©partition d√©taill√©e par zone
                st.write("### üåç R√©partition g√©ographique et calcul de dette")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.write("#### üá´üá∑ France")
                    st.metric("Abonn√©s", len(abo_1an_france))
                    st.metric("Magazines restants", magazines_france)
                    st.write(f"**Prix abo 1 an :** 54.96 ‚Ç¨")
                    st.write(f"**Prix/magazine :** {prix_magazine_france:.2f} ‚Ç¨")
                    st.write(f"**Calcul :** {magazines_france} √ó {prix_magazine_france:.2f} ‚Ç¨")
                    st.success(f"**Dette France : {dette_france:.2f} ‚Ç¨**")
                
                with col2:
                    st.write("#### üá™üá∫ Europe")
                    st.metric("Abonn√©s", len(abo_1an_europe))
                    st.metric("Magazines restants", magazines_europe)
                    st.write(f"**Prix abo 1 an :** 78.96 ‚Ç¨")
                    st.write(f"**Prix/magazine :** {prix_magazine_europe:.2f} ‚Ç¨")
                    st.write(f"**Calcul :** {magazines_europe} √ó {prix_magazine_europe:.2f} ‚Ç¨")
                    st.success(f"**Dette Europe : {dette_europe:.2f} ‚Ç¨**")
                
                with col3:
                    st.write("#### üåç Monde")
                    st.metric("Abonn√©s", len(abo_1an_monde))
                    st.metric("Magazines restants", magazines_monde)
                    st.write(f"**Prix abo 1 an :** 114.96 ‚Ç¨")
                    st.write(f"**Prix/magazine :** {prix_magazine_monde:.2f} ‚Ç¨")
                    st.write(f"**Calcul :** {magazines_monde} √ó {prix_magazine_monde:.2f} ‚Ç¨")
                    st.success(f"**Dette Monde : {dette_monde:.2f} ‚Ç¨**")
                
                # R√©sum√© final
                st.write("---")
                st.write("### üíº R√©sum√© financier")
                summary_col1, summary_col2 = st.columns(2)
                with summary_col1:
                    st.info(f"""
                    **D√©tail des dettes :**
                    - France : {dette_france:.2f} ‚Ç¨
                    - Europe : {dette_europe:.2f} ‚Ç¨
                    - Monde : {dette_monde:.2f} ‚Ç¨
                    """)
                with summary_col2:
                    st.error(f"""
                    **DETTE TOTALE**  
                    ## {dette_totale:.2f} ‚Ç¨
                    """)
                
            else:
                st.info("‚ÑπÔ∏è Aucun abonnement 1 an trouv√© dans les donn√©es.")
        else:
            st.warning("‚ö†Ô∏è Colonne 'Line title' manquante. Impossible d'analyser les abonnements 1 an.")
        
        # Option d'exportation
        st.write("## üíæ Exportation des donn√©es")

        # Fonction pour pr√©parer le format final (SANS Type d'abonnement et Magazines Restants)
        def prepare_final_files(df):
            """Pr√©pare le fichier final avec les colonnes n√©cessaires et renomm√©es."""
            column_mapping = {
                "ID": "Customer ID",
                "Customer name": "Delivery name",
                "Delivery address 1": "Delivery address 1",
                "Delivery address 2": "Delivery address 2",
                "Delivery zip": "Delivery zip",
                "Delivery city": "Delivery city",
                "Delivery province code": "Delivery province code",
                "Delivery country code": "Delivery country code",
                "Billing country": "Billing country",
                "Delivery interval count": "Quantity"
            }
            
            # S'assurer que toutes les colonnes n√©cessaires existent
            for col in column_mapping.keys():
                if col not in df.columns:
                    df[col] = None  # Ajouter une colonne vide si elle n'existe pas
            
            # S√©lectionner et renommer les colonnes
            df = df[list(column_mapping.keys())].rename(columns=column_mapping)
            
            # Remplir la colonne Billing country pour la France si elle est vide
            df['Billing country'] = df.apply(
                lambda row: "FRANCE" if pd.isnull(row['Billing country']) and row['Delivery country code'] == "FR" else row['Billing country'],
                axis=1
            )
            
            final_columns = [
                "Customer ID", "Delivery name", "Delivery address 1", "Delivery address 2",
                "Delivery zip", "Delivery city", "Delivery province code",
                "Delivery country code", "Billing country", "Quantity"
            ]
            return df[final_columns]

        # Cr√©er les dataframes s√©par√©s pour France et √âtranger
        if active_df is not None and cancelled_df is not None:
            # S'assurer que valid_cancelled_df existe
            if 'valid_cancelled_df' not in locals() and 'valid_cancelled_df' not in globals():
                valid_cancelled_df = cancelled_df
    
            # Combiner actifs et annul√©s
            all_df = pd.concat([active_df, valid_cancelled_df], ignore_index=True)
            
            # Calculer les magazines restants AVANT de pr√©parer les fichiers finaux
            all_df = calculate_remaining_magazines(all_df)
            
            # V√©rification finale pour les entr√©es de test
            all_df = remove_test_entries(all_df)
            
            # Cr√©er le fichier sp√©cial pour les abonnements 1 an avec calcul de dette
            if 'Line title' in all_df.columns:
                # Filtrer uniquement les abonnements 1 an
                abo_1an_mask = all_df['Line title'].str.contains('1 an', case=False, na=False, regex=True)
                debt_df = all_df[abo_1an_mask].copy()
                
                if not debt_df.empty:
                    # Fonction pour d√©terminer le prix selon la zone
                    def get_price_info(row):
                        if is_france(row):
                            return 54.96, 54.96 / 12, 'France'
                        elif is_europe(row):
                            return 78.96, 78.96 / 12, 'Europe'
                        else:
                            return 114.96, 114.96 / 12, 'Monde'
                    
                    # Calculer les prix et la dette pour chaque ligne
                    debt_df[['Prix abo 1 an', 'Prix par magazine', 'Zone']] = debt_df.apply(
                        lambda row: pd.Series(get_price_info(row)), axis=1
                    )
                    
                    # Calculer la dette individuelle
                    debt_df['Dette (Magazine √ó Prix)'] = debt_df['Magazines Restants'] * debt_df['Prix par magazine']
                    
                    # S√©lectionner et r√©organiser les colonnes pour le fichier final
                    debt_report = debt_df[[
                        'Customer name',
                        'Zone',
                        'Magazines Restants',
                        'Prix abo 1 an',
                        'Prix par magazine',
                        'Dette (Magazine √ó Prix)'
                    ]].copy()
                    
                    # Renommer pour plus de clart√©
                    debt_report.columns = [
                        'Nom Pr√©nom',
                        'Zone',
                        'Magazines Restants',
                        'Prix Abonnement 1 an (‚Ç¨)',
                        'Prix par Magazine (‚Ç¨)',
                        'Dette Totale (‚Ç¨)'
                    ]
                    
                    # Arrondir les prix √† 2 d√©cimales
                    debt_report['Prix Abonnement 1 an (‚Ç¨)'] = debt_report['Prix Abonnement 1 an (‚Ç¨)'].round(2)
                    debt_report['Prix par Magazine (‚Ç¨)'] = debt_report['Prix par Magazine (‚Ç¨)'].round(2)
                    debt_report['Dette Totale (‚Ç¨)'] = debt_report['Dette Totale (‚Ç¨)'].round(2)
                    
                    # Afficher un aper√ßu
                    st.write("## üí∞ Rapport de Dette - Abonnements 1 an")
                    st.write(f"üìä **{len(debt_report)} abonn√©s 1 an avec dette calcul√©e**")
                    st.dataframe(debt_report)
                    
                    # Statistiques rapides
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Dette totale", f"{debt_report['Dette Totale (‚Ç¨)'].sum():.2f} ‚Ç¨")
                    with col2:
                        st.metric("Dette moyenne", f"{debt_report['Dette Totale (‚Ç¨)'].mean():.2f} ‚Ç¨")
                    with col3:
                        st.metric("Total magazines", int(debt_report['Magazines Restants'].sum()))
            
            # Pr√©parer le format final (sans Type d'abonnement et Magazines Restants)
            all_df_export = prepare_final_files(all_df)

            # V√©rification ultime des entr√©es de test
            name_pattern = r"Brice N'?Guessan"
            mask = all_df_export['Delivery name'].str.contains(name_pattern, case=False, na=False, regex=True)
            test_count = mask.sum()
            if test_count > 0:
                # Les supprimer
                all_df_export = all_df_export[~mask]
                st.info(f"‚ÑπÔ∏è {test_count} entr√©es de test suppl√©mentaires ont √©t√© √©limin√©es.")
            
            # S√©parer par pays
            france_df = all_df_export[all_df_export.apply(is_france, axis=1)]
            etranger_df = all_df_export[~all_df_export.apply(is_france, axis=1)]
            
            st.write(f"üìä **R√©partition des abonnements (tous types) :**")
            st.write(f"- France : {len(france_df)} abonnements")
            st.write(f"- √âtranger : {len(etranger_df)} abonnements")
            
            # Afficher un aper√ßu
            st.write(f"üìå **Donn√©es finales pour la France :**")
            st.dataframe(france_df)

            st.write(f"üìå **Donn√©es finales pour l'√©tranger :**")
            st.dataframe(etranger_df)

        # Colonnes d'export (3 colonnes maintenant)
        col1, col2, col3 = st.columns(3)

        with col1:
            st.write("### üá´üá∑ Abonnements France")
            if st.button("Exporter le fichier France"):
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                
                # D√©finir le nom du fichier
                fr_filename = f"{file_prefix}_france_{timestamp}.xlsx" if file_prefix else f"france_{timestamp}.xlsx"
                
                # Cr√©er un buffer pour stocker le fichier Excel
                buffer = io.BytesIO()
                with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
                    france_df.to_excel(writer, index=False, sheet_name='Abonnements France')
                buffer.seek(0)
                
                # Proposer le t√©l√©chargement
                st.download_button(
                    label="üì• T√©l√©charger les abonnements France",
                    data=buffer,
                    file_name=fr_filename,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
                
                st.success(f"‚úÖ Fichier France pr√™t √† √™tre t√©l√©charg√© ({len(france_df)} abonnements)")

        with col2:
            st.write("### üåç Abonnements √âtranger")
            if st.button("Exporter le fichier √âtranger"):
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                
                # D√©finir le nom du fichier
                int_filename = f"{file_prefix}_etranger_{timestamp}.xlsx" if file_prefix else f"etranger_{timestamp}.xlsx"
                
                # Cr√©er un buffer pour stocker le fichier Excel
                buffer = io.BytesIO()
                with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
                    etranger_df.to_excel(writer, index=False, sheet_name='Abonnements Etranger')
                buffer.seek(0)
                
                # Proposer le t√©l√©chargement
                st.download_button(
                    label="üì• T√©l√©charger les abonnements √âtranger",
                    data=buffer,
                    file_name=int_filename,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
                
                st.success(f"‚úÖ Fichier √âtranger pr√™t √† √™tre t√©l√©charg√© ({len(etranger_df)} abonnements)")

        with col3:
            st.write("### üí∞ Rapport Dette 1 an")
            if 'debt_report' in locals():
                if st.button("Exporter le rapport de dette"):
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    
                    # D√©finir le nom du fichier
                    debt_filename = f"{file_prefix}_dette_1an_{timestamp}.xlsx" if file_prefix else f"dette_1an_{timestamp}.xlsx"
                    
                    # Cr√©er un buffer pour stocker le fichier Excel
                    buffer = io.BytesIO()
                    with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
                        debt_report.to_excel(writer, index=False, sheet_name='Dette Abonnements 1 an')
                    buffer.seek(0)
                    
                    # Proposer le t√©l√©chargement
                    st.download_button(
                        label="üì• T√©l√©charger le rapport de dette",
                        data=buffer,
                        file_name=debt_filename,
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                    
                    st.success(f"‚úÖ Rapport de dette pr√™t ({len(debt_report)} abonn√©s)")
            else:
                st.info("‚ÑπÔ∏è Aucun abonnement 1 an trouv√© pour le rapport de dette")
